# 写在前面：
前面的博文已经提过，在上个月我参加了第四届泰迪杯数据挖掘竞赛，做的是A题，跟OCR系统有些联系，还承诺过会把最终的结果开源。最近忙于毕业、搬东西，一直没空整理这些内容，现在抽空整理一下。

# 把结果发出来，
并不是因为结果有多厉害、多先进（相反，当我对比了百度的这篇论文《基于深度学习的图像识别进展：百度的若干实践》之后，才发现论文的内容本质上还是传统那一套，远远还跟不上时代的潮流），而是因为虽然OCR技术可以说比较成熟了，但网络上根本就没有对OCR系统进行较为详细讲解的文章，而本文就权当补充这部分内容吧。我一直认为，技术应该要开源才能得到发展（当然，在中国这一点也确实值得商榷，因为开源很容易造成山寨），不管是数学物理研究还是数据挖掘，我大多数都会发表到博客中，与大家交流。
言归正传，虽然说结果并不优秀，但总的来说，我们还是比较完整地实现了一个初步能用的OCR系统，换言之，基本上搭建一个OCR系统该做的步骤我们都做了，至于做得好不好，那就只能说差强人意了。文章的叙述中可能有一些夸张的修辞手法，望读者自行甄别哈。

# 下面是我们的论文摘要

我们设计了一系列的算法，完成了文字特征提取、文字定位等工作，并基于卷积神经网络(CNN)建立了字符识别模型，最后结合统计语言模型来提升效果，成功构建了一个**完整的OCR(光学字符识别)系统**.

在特征提取方面，我们抛弃了传统的“边缘检测+腐蚀膨胀”的方法，**基于一些基本假设，通过灰度聚类、图层分解、去噪等步骤**，得到了良好的文字特征. 这部分文字特征既可以用于第二步做**文字定位**，又可以直接输入到第三步的模型中进行识别，而不用做额外的特征提取工作.

在**文字定位**方面，我们通过邻近搜索的方法先整合特征碎片，得到了单行的文字特征，然后通过前后统计的方法将单行的文字切割为单个字符. 测试表明，这种切割思路能够很好地应对中英文混排的文字切割.

在光学识别方面，我们基于CNN的深度学习模型建立了**单字识别模型**，自行生成了140万的样本进行训练，最终得到了一个良好的单字识别模型，训练正确率为99.7%，测试正确率为92.1%，即便增大图片噪音到15%，也能有90%左右的正确率.

最后，为了在前面的工作的基础上再次提升效果，我们结合了**语言模型**，通过微信的数十万文本计算了常见汉字的转移概率矩阵，由Viterbi算法动态规划，得到最优的识别组合.

将以上四部分工作结合起来，就是一个完整的OCR系统. 经过测试，我们的系统对印刷文字的识别有着不错的效果，可以作为电商、微信等平台的图片文字识别工具.

# 参考文献

[1] 李萌;基于多尺度 Gabor 滤波器和 BP 神经网络的文本检测算法研究;计算机软件与理论;2007

[2] 核密度估计;https://zh.wikipedia.org/zh-cn/核密度估计;维基百科

[3] Xavier Glorot, Antoine Bordes, Yoshua Bengio ; Deep Sparse Recti er Neural Networks

[4] Alex Krizhevsky,Ilya Sutskever,Geo rey E. Hinton ; ImageNet Classi cation with Deep Convolutional Neural Networks

[5] Dropout: A Simple Way to Prevent Neural Networks from Overfitting

[6] 吴军;《数学之美》(第二版);第 3 章

[7] 吴军;《数学之美》(第二版);第 26 章


转载到请包括本文地址：http://spaces.ac.cn/archives/3774/
